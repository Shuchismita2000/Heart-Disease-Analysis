{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Heart_Data_Hungary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp trestbps chol fbs restecg thalach exang  oldpeak slope ca  \\\n",
       "0   28    1   2      130  132   0       2     185     0      0.0     ?  ?   \n",
       "1   29    1   2      120  243   0       0     160     0      0.0     ?  ?   \n",
       "2   29    1   2      140    ?   0       0     170     0      0.0     ?  ?   \n",
       "3   30    0   1      170  237   0       1     170     0      0.0     ?  ?   \n",
       "4   31    0   2      100  219   0       1     150     0      0.0     ?  ?   \n",
       "\n",
       "  thal  target  \n",
       "0    ?       0  \n",
       "1    ?       0  \n",
       "2    ?       0  \n",
       "3    6       0  \n",
       "4    ?       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>294.000000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>294.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47.826531</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>2.982993</td>\n",
       "      <td>0.586054</td>\n",
       "      <td>0.360544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.811812</td>\n",
       "      <td>0.447533</td>\n",
       "      <td>0.965117</td>\n",
       "      <td>0.908648</td>\n",
       "      <td>0.480977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp     oldpeak      target\n",
       "count  294.000000  294.000000  294.000000  294.000000  294.000000\n",
       "mean    47.826531    0.724490    2.982993    0.586054    0.360544\n",
       "std      7.811812    0.447533    0.965117    0.908648    0.480977\n",
       "min     28.000000    0.000000    1.000000    0.000000    0.000000\n",
       "25%     42.000000    0.000000    2.000000    0.000000    0.000000\n",
       "50%     49.000000    1.000000    3.000000    0.000000    0.000000\n",
       "75%     54.000000    1.000000    4.000000    1.000000    1.000000\n",
       "max     66.000000    1.000000    4.000000    5.000000    1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.replace('?','missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA:\n",
      " missing    291\n",
      "0            3\n",
      "Name: ca, dtype: int64\n",
      "Slope:\n",
      " missing    190\n",
      "2           91\n",
      "1           12\n",
      "3            1\n",
      "Name: slope, dtype: int64\n",
      "Thal:\n",
      " missing    266\n",
      "7           11\n",
      "6           10\n",
      "3            7\n",
      "Name: thal, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('CA:\\n',data1['ca'].value_counts())\n",
    "print('Slope:\\n',data1['slope'].value_counts())\n",
    "print('Thal:\\n',data1['thal'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    188\n",
       "1    106\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIVING ABRUPT VALUES IN MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data1.replace('missing','120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data1.drop(['target'],axis=1)\n",
    "Y=data1[['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HANDLENING IMBALANCED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "x_over, y_over = oversample.fit_resample(X, Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "x_smote, y_smote = smote.fit_resample(X, Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler()\n",
    "x_under, y_under = undersample.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Shape Of X</th>\n",
       "      <th>Shape of Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imbalance data</td>\n",
       "      <td>(294, 13)</td>\n",
       "      <td>(294, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Over</td>\n",
       "      <td>(376, 13)</td>\n",
       "      <td>(376, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>(376, 13)</td>\n",
       "      <td>(376, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Under</td>\n",
       "      <td>(212, 13)</td>\n",
       "      <td>(212, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Methods Shape Of X Shape of Y\n",
       "0  Imbalance data  (294, 13)   (294, 1)\n",
       "1     Random Over  (376, 13)   (376, 1)\n",
       "2           SMOTE  (376, 13)   (376, 1)\n",
       "3    Random Under  (212, 13)   (212, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = {'Methods':['Imbalance data','Random Over','SMOTE','Random Under'],\n",
    "        'Shape Of X':[X.shape,x_over.shape,x_smote.shape,x_under.shape],\n",
    "       'Shape of Y':[Y.shape,y_over.shape,y_smote.shape,y_under.shape]}\n",
    "table=pd.DataFrame(df)\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLITING THE DATASET FOR TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train, Y_test= train_test_split(X,Y,test_size = 0.3 , random_state = 0 )\n",
    "\n",
    "#over\n",
    "X_train_over,X_test_over,Y_train_over, Y_test_over= train_test_split(x_over,y_over,test_size = 0.3 , random_state = 0 )\n",
    "\n",
    "#smote\n",
    "X_train_smote,X_test_smote,Y_train_smote, Y_test_smote= train_test_split(x_smote,y_smote,test_size = 0.3 , random_state = 0 )\n",
    "\n",
    "#under\n",
    "X_train_under,X_test_under,Y_train_under, Y_test_under= train_test_split(x_under,y_under,test_size = 0.3 , random_state = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#over\n",
    "X_train_over = sc.fit_transform(X_train_over)\n",
    "X_test_over = sc.transform(X_test_over)\n",
    "\n",
    "#smote\n",
    "X_train_smote = sc.fit_transform(X_train_smote)\n",
    "X_test_smote = sc.transform(X_test_smote)\n",
    "\n",
    "#under\n",
    "X_train_under = sc.fit_transform(X_train_under)\n",
    "X_test_under = sc.transform(X_test_under)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#define model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_a=LogisticRegression()\n",
    "lr_b=LogisticRegression()\n",
    "lr_c=LogisticRegression()\n",
    "lr_d=LogisticRegression()\n",
    "# fit model on labeled dataset\n",
    "lr_a.fit(X_train,Y_train)\n",
    "lr_b.fit(X_train_over,Y_train_over)\n",
    "lr_c.fit(X_train_smote,Y_train_smote)\n",
    "lr_d.fit(X_train_under,Y_train_under)\n",
    "# predict\n",
    "y_pred_1_a=lr_a.predict(X_test)\n",
    "y_pred_1_b=lr_b.predict(X_test_over)\n",
    "y_pred_1_c=lr_c.predict(X_test_smote)\n",
    "y_pred_1_d=lr_d.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model \n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_a=DecisionTreeClassifier()\n",
    "clf_b=DecisionTreeClassifier()\n",
    "clf_c=DecisionTreeClassifier()\n",
    "clf_d=DecisionTreeClassifier()\n",
    "# fit model on labeled dataset\n",
    "clf_a.fit(X_train,Y_train)\n",
    "clf_b.fit(X_train_over,Y_train_over)\n",
    "clf_c.fit(X_train_smote,Y_train_smote)\n",
    "clf_d.fit(X_train_under,Y_train_under)\n",
    "# predict\n",
    "y_pred_2_a=clf_a.predict(X_test)\n",
    "y_pred_2_b=clf_b.predict(X_test_over)\n",
    "y_pred_2_c=clf_c.predict(X_test_smote)\n",
    "y_pred_2_d=clf_d.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-d00340949887>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc_a.fit(X_train,Y_train)\n",
      "<ipython-input-19-d00340949887>:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc_b.fit(X_train_over,Y_train_over)\n",
      "<ipython-input-19-d00340949887>:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc_c.fit(X_train_smote,Y_train_smote)\n",
      "<ipython-input-19-d00340949887>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc_d.fit(X_train_under,Y_train_under)\n"
     ]
    }
   ],
   "source": [
    "#define model \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_a=RandomForestClassifier(n_estimators=10, criterion = 'entropy',random_state=0)\n",
    "rfc_b=RandomForestClassifier(n_estimators=10, criterion = 'entropy',random_state=0)\n",
    "rfc_c=RandomForestClassifier(n_estimators=10, criterion = 'entropy',random_state=0)\n",
    "rfc_d=RandomForestClassifier(n_estimators=10, criterion = 'entropy',random_state=0)\n",
    "# fit model on labeled dataset\n",
    "rfc_a.fit(X_train,Y_train)\n",
    "rfc_b.fit(X_train_over,Y_train_over)\n",
    "rfc_c.fit(X_train_smote,Y_train_smote)\n",
    "rfc_d.fit(X_train_under,Y_train_under)\n",
    "# predict\n",
    "y_pred_3_a=rfc_a.predict(X_test)\n",
    "y_pred_3_b=rfc_b.predict(X_test_over)\n",
    "y_pred_3_c=rfc_c.predict(X_test_smote)\n",
    "y_pred_3_d=rfc_d.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#define model \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_a=GaussianNB()\n",
    "nb_b=GaussianNB()\n",
    "nb_c=GaussianNB()\n",
    "nb_d=GaussianNB()\n",
    "# fit model on labeled dataset\n",
    "nb_a.fit(X_train,Y_train)\n",
    "nb_b.fit(X_train_over,Y_train_over)\n",
    "nb_c.fit(X_train_smote,Y_train_smote)\n",
    "nb_d.fit(X_train_under,Y_train_under)\n",
    "# predict\n",
    "y_pred_4_a=nb_a.predict(X_test)\n",
    "y_pred_4_b=nb_b.predict(X_test_over)\n",
    "y_pred_4_c=nb_c.predict(X_test_smote)\n",
    "y_pred_4_d=nb_d.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY ADABOOSTCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#define model \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc_a=AdaBoostClassifier()\n",
    "abc_b=AdaBoostClassifier()\n",
    "abc_c=AdaBoostClassifier()\n",
    "abc_d=AdaBoostClassifier()\n",
    "# fit model on labeled dataset\n",
    "abc_a.fit(X_train,Y_train)\n",
    "abc_b.fit(X_train_over,Y_train_over)\n",
    "abc_c.fit(X_train_smote,Y_train_smote)\n",
    "abc_d.fit(X_train_under,Y_train_under)\n",
    "# predict\n",
    "y_pred_5_a=abc_a.predict(X_test)\n",
    "y_pred_5_b=abc_b.predict(X_test_over)\n",
    "y_pred_5_c=abc_c.predict(X_test_smote)\n",
    "y_pred_5_d=abc_d.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY GRADIENTBOOSTINGCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#define model \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_a=GradientBoostingClassifier()\n",
    "gbc_b=GradientBoostingClassifier()\n",
    "gbc_c=GradientBoostingClassifier()\n",
    "gbc_d=GradientBoostingClassifier()\n",
    "# fit model on labeled dataset\n",
    "gbc_a.fit(X_train,Y_train)\n",
    "gbc_b.fit(X_train_over,Y_train_over)\n",
    "gbc_c.fit(X_train_smote,Y_train_smote)\n",
    "gbc_d.fit(X_train_under,Y_train_under)\n",
    "# predict\n",
    "y_pred_6_a=gbc_a.predict(X_test)\n",
    "y_pred_6_b=gbc_b.predict(X_test_over)\n",
    "y_pred_6_c=gbc_c.predict(X_test_smote)\n",
    "y_pred_6_d=gbc_d.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY XGBCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:26:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb=XGBClassifier()\n",
    "xgb.fit(X_train,Y_train)\n",
    "y_pred_7= xgb.predict(X_test)\n",
    "\n",
    "#define model \n",
    "from xgboost import XGBClassifier\n",
    "xgb_a=XGBClassifier()\n",
    "xgb_b=XGBClassifier()\n",
    "xgb_c=XGBClassifier()\n",
    "xgb_d=XGBClassifier()\n",
    "# fit model on labeled dataset\n",
    "xgb_a.fit(X_train,Y_train)\n",
    "xgb_b.fit(X_train_over,Y_train_over)\n",
    "xgb_c.fit(X_train_smote,Y_train_smote)\n",
    "xgb_d.fit(X_train_under,Y_train_under)\n",
    "# predict\n",
    "y_pred_7_a=xgb_a.predict(X_test)\n",
    "y_pred_7_b=xgb_b.predict(X_test_over)\n",
    "y_pred_7_c=xgb_c.predict(X_test_smote)\n",
    "y_pred_7_d=xgb_d.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY KNEIGHBORS CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\SHUCHISMITA MALLICK\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc=KNeighborsClassifier()\n",
    "knc.fit(X_train,Y_train)\n",
    "y_pred_8= knc.predict(X_test)\n",
    "\n",
    "#define model \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc_a=KNeighborsClassifier()\n",
    "knc_b=KNeighborsClassifier()\n",
    "knc_c=KNeighborsClassifier()\n",
    "knc_d=KNeighborsClassifier()\n",
    "# fit model on labeled dataset\n",
    "knc_a.fit(X_train,Y_train)\n",
    "knc_b.fit(X_train_over,Y_train_over)\n",
    "knc_c.fit(X_train_smote,Y_train_smote)\n",
    "knc_d.fit(X_train_under,Y_train_under)\n",
    "# predict\n",
    "y_pred_8_a=knc_a.predict(X_test)\n",
    "y_pred_8_b=knc_b.predict(X_test_over)\n",
    "y_pred_8_c=knc_c.predict(X_test_smote)\n",
    "y_pred_8_d=knc_d.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(activation = \"relu\", input_dim =13,units = 52, kernel_initializer = \"uniform\"))\n",
    "classifier.add(Dense(activation = \"relu\", units = 39,kernel_initializer = \"uniform\"))\n",
    "classifier.add(Dense(activation = \"relu\", units = 52,kernel_initializer = \"uniform\"))\n",
    "classifier.add(Dense(activation = \"relu\", units = 26,kernel_initializer = \"uniform\"))\n",
    "classifier.add(Dense(activation = \"sigmoid\", units = 1,kernel_initializer = \"uniform\"))\n",
    "classifier.compile(optimizer = 'adam' , loss = 'binary_crossentropy',metrics = ['accuracy'] )\n",
    "\n",
    "#over\n",
    "classifier_1 = Sequential()\n",
    "classifier_1.add(Dense(activation = \"relu\", input_dim =13,units = 52, kernel_initializer = \"uniform\"))\n",
    "classifier_1.add(Dense(activation = \"relu\", units = 39,kernel_initializer = \"uniform\"))\n",
    "classifier_1.add(Dense(activation = \"relu\", units = 52,kernel_initializer = \"uniform\"))\n",
    "classifier_1.add(Dense(activation = \"relu\", units = 26,kernel_initializer = \"uniform\"))\n",
    "classifier_1.add(Dense(activation = \"sigmoid\", units = 1,kernel_initializer = \"uniform\"))\n",
    "classifier_1.compile(optimizer = 'adam' , loss = 'binary_crossentropy',metrics = ['accuracy'] )\n",
    "\n",
    "#smote\n",
    "classifier_2 = Sequential()\n",
    "classifier_2.add(Dense(activation = \"relu\", input_dim =13,units = 52, kernel_initializer = \"uniform\"))\n",
    "classifier_2.add(Dense(activation = \"relu\", units = 39,kernel_initializer = \"uniform\"))\n",
    "classifier_2.add(Dense(activation = \"relu\", units = 52,kernel_initializer = \"uniform\"))\n",
    "classifier_2.add(Dense(activation = \"relu\", units = 26,kernel_initializer = \"uniform\"))\n",
    "classifier_2.add(Dense(activation = \"sigmoid\", units = 1,kernel_initializer = \"uniform\"))\n",
    "classifier_2.compile(optimizer = 'adam' , loss = 'binary_crossentropy',metrics = ['accuracy'] )\n",
    "\n",
    "#under\n",
    "classifier_3 = Sequential()\n",
    "classifier_3.add(Dense(activation = \"relu\", input_dim =13,units = 52, kernel_initializer = \"uniform\"))\n",
    "classifier_3.add(Dense(activation = \"relu\", units = 39,kernel_initializer = \"uniform\"))\n",
    "classifier_3.add(Dense(activation = \"relu\", units = 52,kernel_initializer = \"uniform\"))\n",
    "classifier_3.add(Dense(activation = \"relu\", units = 26,kernel_initializer = \"uniform\"))\n",
    "classifier_3.add(Dense(activation = \"sigmoid\", units = 1,kernel_initializer = \"uniform\"))\n",
    "classifier_3.compile(optimizer = 'adam' , loss = 'binary_crossentropy',metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.6488\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.6683\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8390\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8732\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8732\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8683\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8732\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8683\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8780\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8780\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.8878\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8780\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8878\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8927\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2950 - accuracy: 0.8927\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.8976\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2817 - accuracy: 0.9073\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2768 - accuracy: 0.9073\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.9122\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.9073\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.9122\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2566 - accuracy: 0.9122\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.9122\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.9171\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9073\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9171\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9122\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9220\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9220\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9171\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9171\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9171\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9171\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9171\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9171\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9220\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9317\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9122\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9220\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9317\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9171\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9122\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9268\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9317\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9366\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9366\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9415\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9366\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.9512\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9415\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9463\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9610\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9610\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.9512\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9610\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9707\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9707\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9707\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9707\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9854\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9659\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9463\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9512\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9610\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.9122\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9610\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9707\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9659\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9707\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9707\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9805\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9756\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9756\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9854\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9805\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9902\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9902\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9805\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9902\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9854\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9902\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9805\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9854\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9805\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9707\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9902\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9707\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 0.9707\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9805\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9902\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9902\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9951\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9951\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9902\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9756\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9902\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9756\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.9512\n",
      "Epoch 1/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5817\n",
      "Epoch 2/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.8251\n",
      "Epoch 3/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8479\n",
      "Epoch 4/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8441\n",
      "Epoch 5/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8517\n",
      "Epoch 6/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8593\n",
      "Epoch 7/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8593\n",
      "Epoch 8/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8593\n",
      "Epoch 9/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8593\n",
      "Epoch 10/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8669\n",
      "Epoch 11/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8745\n",
      "Epoch 12/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8821\n",
      "Epoch 13/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8745\n",
      "Epoch 14/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8821\n",
      "Epoch 15/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8859\n",
      "Epoch 16/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8821\n",
      "Epoch 17/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8821\n",
      "Epoch 18/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8859\n",
      "Epoch 19/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8897\n",
      "Epoch 20/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8783\n",
      "Epoch 21/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8859\n",
      "Epoch 22/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.9011\n",
      "Epoch 23/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8859\n",
      "Epoch 24/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8745\n",
      "Epoch 25/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8859\n",
      "Epoch 26/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8973\n",
      "Epoch 27/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.9011\n",
      "Epoch 28/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.8935\n",
      "Epoch 29/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.9125\n",
      "Epoch 30/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.9011\n",
      "Epoch 31/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.9125\n",
      "Epoch 32/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 0.9163\n",
      "Epoch 33/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9125\n",
      "Epoch 34/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9278\n",
      "Epoch 35/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9125\n",
      "Epoch 36/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9087\n",
      "Epoch 37/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9163\n",
      "Epoch 38/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9163\n",
      "Epoch 39/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9278\n",
      "Epoch 40/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9163\n",
      "Epoch 41/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9163\n",
      "Epoch 42/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9354\n",
      "Epoch 43/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9468\n",
      "Epoch 44/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9354\n",
      "Epoch 45/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.9354\n",
      "Epoch 46/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9392\n",
      "Epoch 47/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9430\n",
      "Epoch 48/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9544\n",
      "Epoch 49/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.9544\n",
      "Epoch 50/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9392\n",
      "Epoch 51/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9468\n",
      "Epoch 52/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9430\n",
      "Epoch 53/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9582\n",
      "Epoch 54/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9506\n",
      "Epoch 55/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9620\n",
      "Epoch 56/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9620\n",
      "Epoch 57/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9658\n",
      "Epoch 58/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9620\n",
      "Epoch 59/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9620\n",
      "Epoch 60/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9734\n",
      "Epoch 61/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9772\n",
      "Epoch 62/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9772\n",
      "Epoch 63/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9734\n",
      "Epoch 64/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9924\n",
      "Epoch 65/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9962\n",
      "Epoch 66/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9962\n",
      "Epoch 67/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9962\n",
      "Epoch 68/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9924\n",
      "Epoch 69/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9810\n",
      "Epoch 71/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9810\n",
      "Epoch 72/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9924\n",
      "Epoch 73/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9962\n",
      "Epoch 74/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.9392\n",
      "Epoch 75/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.9468\n",
      "Epoch 76/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1224 - accuracy: 0.9620\n",
      "Epoch 77/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9734\n",
      "Epoch 78/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9848\n",
      "Epoch 79/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9962\n",
      "Epoch 80/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9962\n",
      "Epoch 81/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9886\n",
      "Epoch 82/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9924\n",
      "Epoch 83/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.4943\n",
      "Epoch 2/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.7871\n",
      "Epoch 3/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8441\n",
      "Epoch 4/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8403\n",
      "Epoch 5/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8517\n",
      "Epoch 6/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8517\n",
      "Epoch 7/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8479\n",
      "Epoch 8/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8555\n",
      "Epoch 9/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8555\n",
      "Epoch 10/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8631\n",
      "Epoch 11/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8669\n",
      "Epoch 12/100\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8593\n",
      "Epoch 13/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8707\n",
      "Epoch 14/100\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8669\n",
      "Epoch 15/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8669\n",
      "Epoch 16/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8631\n",
      "Epoch 17/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8707\n",
      "Epoch 18/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8669\n",
      "Epoch 19/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3160 - accuracy: 0.8669\n",
      "Epoch 20/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8669\n",
      "Epoch 21/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2954 - accuracy: 0.8783\n",
      "Epoch 22/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2877 - accuracy: 0.8783\n",
      "Epoch 23/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2831 - accuracy: 0.8821\n",
      "Epoch 24/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8897\n",
      "Epoch 25/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.8973\n",
      "Epoch 26/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.8973\n",
      "Epoch 27/100\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.9125\n",
      "Epoch 28/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.9240\n",
      "Epoch 29/100\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2125 - accuracy: 0.9278\n",
      "Epoch 30/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2071 - accuracy: 0.9278\n",
      "Epoch 31/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1964 - accuracy: 0.9354\n",
      "Epoch 32/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 0.9354\n",
      "Epoch 33/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9468\n",
      "Epoch 34/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1622 - accuracy: 0.9506\n",
      "Epoch 35/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9544\n",
      "Epoch 36/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9544\n",
      "Epoch 37/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9468\n",
      "Epoch 38/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9620\n",
      "Epoch 39/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1246 - accuracy: 0.9696\n",
      "Epoch 40/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9734\n",
      "Epoch 41/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1054 - accuracy: 0.9696\n",
      "Epoch 42/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9734\n",
      "Epoch 43/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9772\n",
      "Epoch 44/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9544\n",
      "Epoch 45/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9734\n",
      "Epoch 46/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9734\n",
      "Epoch 47/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9848\n",
      "Epoch 48/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9810\n",
      "Epoch 49/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.9620\n",
      "Epoch 50/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9620\n",
      "Epoch 51/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9810\n",
      "Epoch 52/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9734\n",
      "Epoch 53/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9810\n",
      "Epoch 54/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9848\n",
      "Epoch 55/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9924\n",
      "Epoch 56/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9924\n",
      "Epoch 57/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9924\n",
      "Epoch 58/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9924\n",
      "Epoch 59/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9886\n",
      "Epoch 60/100\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9924\n",
      "Epoch 61/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9696\n",
      "Epoch 62/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9696\n",
      "Epoch 63/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9582\n",
      "Epoch 64/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9772\n",
      "Epoch 65/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9848\n",
      "Epoch 66/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9886\n",
      "Epoch 67/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9924\n",
      "Epoch 68/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9962\n",
      "Epoch 69/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9962\n",
      "Epoch 70/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9924\n",
      "Epoch 71/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9886\n",
      "Epoch 72/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9924\n",
      "Epoch 73/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9886\n",
      "Epoch 74/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9924\n",
      "Epoch 75/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9886\n",
      "Epoch 76/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9924\n",
      "Epoch 77/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9962\n",
      "Epoch 78/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9962\n",
      "Epoch 79/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9962\n",
      "Epoch 80/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9962\n",
      "Epoch 82/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9962\n",
      "Epoch 84/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9962\n",
      "Epoch 85/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9962\n",
      "Epoch 89/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9962\n",
      "Epoch 94/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9962\n",
      "Epoch 95/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9962\n",
      "Epoch 96/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.4797\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.8041\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8243\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8581\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8649\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8784\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8851\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8851: 0s - loss: 0.3367 - accuracy: 0.88\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8784\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8919\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8784\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8986\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8851\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.8919\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.9054\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8986\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8986\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8919\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.8986\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8851\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.8986\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9122\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.9054\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9122\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9122\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9122\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9054\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 0.9122\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9122\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9122\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9189\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9189\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9257\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9257\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9257\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9257\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9324\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9324\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9324\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9459\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.9324\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9189\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.9324\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9459\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9459\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9459\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9459\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9459\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9459\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9459\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9459\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9459\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9459\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9527\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9527\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9662\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9797\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9730\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9730\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9797\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9797\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9865\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0480 - accuracy: 0.9797\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9865\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9797\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9797\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9865\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9797\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9865\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9797\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9865\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9797\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9865\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9797\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9865\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9865\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9865\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9865\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9865\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9865\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9865\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9865\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9865\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9865\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9865\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9865\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9865\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9865\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9865\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.9865\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9865\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9865\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9865\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9797\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7616 - accuracy: 0.9189\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.8919\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8851\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.9189\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9189\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19cee384ee0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train , Y_train, batch_size = 4 ,epochs = 100 )\n",
    "\n",
    "#over\n",
    "classifier_1.fit(X_train_over , Y_train_over, batch_size = 4 ,epochs = 100 )\n",
    "\n",
    "#smote\n",
    "classifier_2.fit(X_train_smote , Y_train_smote, batch_size = 4 ,epochs = 100 )\n",
    "\n",
    "#under\n",
    "classifier_3.fit(X_train_under , Y_train_under, batch_size = 4 ,epochs = 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_9_a = classifier.predict(X_test)\n",
    "y_pred_9_a = (y_pred_9_a> 0.5)\n",
    "\n",
    "#over\n",
    "y_pred_9_b = classifier_1.predict(X_test_over)\n",
    "y_pred_9_b = (y_pred_9_b  > 0.5)\n",
    "\n",
    "#smote\n",
    "y_pred_9_c = classifier_2.predict(X_test_smote)\n",
    "y_pred_9_c= (y_pred_9_c > 0.5)\n",
    "\n",
    "#under\n",
    "y_pred_9_d = classifier_3.predict(X_test_under)\n",
    "y_pred_9_d = (y_pred_9_d > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[46  5]\n",
      " [16 22]]\n",
      "Confusion Matrix for Random Over :\n",
      " [[51  6]\n",
      " [ 8 48]]\n",
      "Confusion Matrix for SMOTE :\n",
      " [[48  9]\n",
      " [11 45]]\n",
      "Confusion Matrix for Random Under :\n",
      " [[23  8]\n",
      " [ 6 27]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for neural network\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test,y_pred_9_a)\n",
    "print('Confusion Matrix :\\n',cm)\n",
    "\n",
    "#over\n",
    "cm_over = confusion_matrix(Y_test_over,y_pred_9_b)\n",
    "print('Confusion Matrix for Random Over :\\n',cm_over)\n",
    "\n",
    "#smote\n",
    "cm_smote = confusion_matrix(Y_test_smote,y_pred_9_c)\n",
    "print('Confusion Matrix for SMOTE :\\n',cm_smote)\n",
    "\n",
    "#under\n",
    "cm_under = confusion_matrix(Y_test_under,y_pred_9_d)\n",
    "print('Confusion Matrix for Random Under :\\n',cm_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_a=accuracy_score(Y_test,y_pred_1_a)\n",
    "D_a=accuracy_score(Y_test,y_pred_2_a)\n",
    "N_a=accuracy_score(Y_test,y_pred_3_a)\n",
    "R_a=accuracy_score(Y_test,y_pred_4_a)\n",
    "A_a=accuracy_score(Y_test,y_pred_5_a)\n",
    "G_a=accuracy_score(Y_test,y_pred_6_a)\n",
    "X_a=accuracy_score(Y_test,y_pred_7_a)\n",
    "K_a=accuracy_score(Y_test,y_pred_8_a)\n",
    "NN_a=(cm[0][0]+cm[1][1])/(cm[0][1] + cm[1][0] +cm[0][0] +cm[1][1])\n",
    "\n",
    "\n",
    "L_b=accuracy_score(Y_test_over,y_pred_1_b)\n",
    "D_b=accuracy_score(Y_test_over,y_pred_2_b)\n",
    "N_b=accuracy_score(Y_test_over,y_pred_3_b)\n",
    "R_b=accuracy_score(Y_test_over,y_pred_4_b)\n",
    "A_b=accuracy_score(Y_test_over,y_pred_5_b)\n",
    "G_b=accuracy_score(Y_test_over,y_pred_6_b)\n",
    "X_b=accuracy_score(Y_test_over,y_pred_7_b)\n",
    "K_b=accuracy_score(Y_test_over,y_pred_8_b)\n",
    "NN_b=(cm_over[0][0]+cm_over[1][1])/(cm_over[0][1] + cm_over[1][0] +cm_over[0][0] +cm_over[1][1])\n",
    "\n",
    "L_c=accuracy_score(Y_test_smote,y_pred_1_c)\n",
    "D_c=accuracy_score(Y_test_smote,y_pred_2_c)\n",
    "N_c=accuracy_score(Y_test_smote,y_pred_3_c)\n",
    "R_c=accuracy_score(Y_test_smote,y_pred_4_c)\n",
    "A_c=accuracy_score(Y_test_smote,y_pred_5_c)\n",
    "G_c=accuracy_score(Y_test_smote,y_pred_6_c)\n",
    "X_c=accuracy_score(Y_test_smote,y_pred_7_c)\n",
    "K_c=accuracy_score(Y_test_smote,y_pred_8_c)\n",
    "NN_c=(cm_smote [0][0]+cm_smote [1][1])/(cm_smote [0][1] + cm_smote [1][0] +cm_smote [0][0] +cm_smote [1][1])\n",
    "\n",
    "\n",
    "L_d=accuracy_score(Y_test_under,y_pred_1_d)\n",
    "D_d=accuracy_score(Y_test_under,y_pred_2_d)\n",
    "N_d=accuracy_score(Y_test_under,y_pred_3_d)\n",
    "R_d=accuracy_score(Y_test_under,y_pred_4_d)\n",
    "A_d=accuracy_score(Y_test_under,y_pred_5_d)\n",
    "G_d=accuracy_score(Y_test_under,y_pred_6_d)\n",
    "X_d=accuracy_score(Y_test_under,y_pred_7_d)\n",
    "K_d=accuracy_score(Y_test_under,y_pred_8_d)\n",
    "NN_d=(cm_under[0][0]+cm_under[1][1])/(cm_under[0][1] + cm_under[1][0] +cm_under[0][0] +cm_under[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df={'CLASSIFIER':['LOGISTIC REGRESSION','DECISION TREE','NAIVE BAYES',\n",
    "                  'RANDOM FOREST','ADABOOST CLASSIFIER','GRADIENTBOOST CLASSIFIER',\n",
    "                  'XGB CLASSIFIER','KNEIGHBORS CLASSIFIER','NEURAL NETWORK'],\n",
    "     'IMBALANCE DATA':[L_a,D_a,R_a,N_a,A_a,G_a,X_a,K_a,NN_a],\n",
    "    'RANDOM OVER':[L_b,D_b,R_b,N_b,A_b,G_b,X_b,K_b,NN_b],\n",
    "    'SMOTE':[L_c,D_c,R_c,N_c,A_c,G_c,X_c,K_c,NN_c],\n",
    "    'RANDOM UNDER':[L_d,D_d,R_d,N_d,A_d,G_d,X_d,K_d,NN_d],\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASSIFIER</th>\n",
       "      <th>IMBALANCE DATA</th>\n",
       "      <th>RANDOM OVER</th>\n",
       "      <th>SMOTE</th>\n",
       "      <th>RANDOM UNDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOGISTIC REGRESSION</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DECISION TREE</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.796460</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NAIVE BAYES</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.725664</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.823009</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADABOOST CLASSIFIER</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GRADIENTBOOST CLASSIFIER</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.849558</td>\n",
       "      <td>0.858407</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB CLASSIFIER</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNEIGHBORS CLASSIFIER</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NEURAL NETWORK</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.823009</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CLASSIFIER  IMBALANCE DATA  RANDOM OVER     SMOTE  \\\n",
       "0       LOGISTIC REGRESSION        0.797753     0.787611  0.787611   \n",
       "1             DECISION TREE        0.797753     0.796460  0.814159   \n",
       "2               NAIVE BAYES        0.764045     0.752212  0.725664   \n",
       "3             RANDOM FOREST        0.808989     0.823009  0.831858   \n",
       "4       ADABOOST CLASSIFIER        0.786517     0.831858  0.805310   \n",
       "5  GRADIENTBOOST CLASSIFIER        0.808989     0.849558  0.858407   \n",
       "6            XGB CLASSIFIER        0.820225     0.840708  0.814159   \n",
       "7     KNEIGHBORS CLASSIFIER        0.786517     0.805310  0.814159   \n",
       "8            NEURAL NETWORK        0.764045     0.876106  0.823009   \n",
       "\n",
       "   RANDOM UNDER  \n",
       "0      0.734375  \n",
       "1      0.750000  \n",
       "2      0.531250  \n",
       "3      0.765625  \n",
       "4      0.703125  \n",
       "5      0.781250  \n",
       "6      0.765625  \n",
       "7      0.765625  \n",
       "8      0.781250  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.DataFrame(df)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from eiffel2 import builder\n",
    "builder([13,13,39,26,1],net_colors=['green','yellow','red','blue'],bmode='night')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
